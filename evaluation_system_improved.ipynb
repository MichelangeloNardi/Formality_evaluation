{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pavlick and Tetreault Formality Scores (0 -> informal, 1 -> formal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"osyvokon/pavlick-formality-scores\")\n",
    "\n",
    "train_data = dataset[\"train\"]\n",
    "test_data = dataset[\"test\"] \n",
    "\n",
    "df_train = pd.DataFrame(train_data.to_pandas())  \n",
    "df_test = pd.DataFrame(test_data.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>Tang was employed at private-equity firm Fried...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news</td>\n",
       "      <td>1.0</td>\n",
       "      <td>San Francisco Mayor Gavin Newsom's withdrawal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>answers</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>lol nothing worrying about that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>0.0</td>\n",
       "      <td>She told Price she wanted to join the Police E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news</td>\n",
       "      <td>1.8</td>\n",
       "      <td>The prime minister is keen to use the autumn p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>blog</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Those competencies include mastering fundament...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>news</td>\n",
       "      <td>0.8</td>\n",
       "      <td>His platform contains plans to fund drainage p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>answers</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>\"It's a start.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>news</td>\n",
       "      <td>0.6</td>\n",
       "      <td>\"She is not asking for anything over the top, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>news</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Justice Dinakaran had maintained that he had n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    domain  avg_score                                           sentence\n",
       "0     news       -0.6  Tang was employed at private-equity firm Fried...\n",
       "1     news        1.0  San Francisco Mayor Gavin Newsom's withdrawal ...\n",
       "2  answers       -2.8                   lol nothing worrying about that.\n",
       "3     news        0.0  She told Price she wanted to join the Police E...\n",
       "4     news        1.8  The prime minister is keen to use the autumn p...\n",
       "5     blog        1.0  Those competencies include mastering fundament...\n",
       "6     news        0.8  His platform contains plans to fund drainage p...\n",
       "7  answers       -1.8                                    \"It's a start.\"\n",
       "8     news        0.6  \"She is not asking for anything over the top, ...\n",
       "9     news        0.8  Justice Dinakaran had maintained that he had n..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9274.000000\n",
       "mean       -0.044080\n",
       "std         1.349061\n",
       "min        -3.000000\n",
       "25%        -1.000000\n",
       "50%         0.000000\n",
       "75%         1.000000\n",
       "max         3.000000\n",
       "Name: avg_score, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data exploration of avg_score\n",
    "df_train[\"avg_score\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the avg_score\n",
    "df_train[\"normalized_score\"] = (df_train[\"avg_score\"] + 3) / 6\n",
    "df_test[\"normalized_score\"] = (df_test[\"avg_score\"] + 3) / 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11274\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>formality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tang was employed at private-equity firm Fried...</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>San Francisco Mayor Gavin Newsom's withdrawal ...</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lol nothing worrying about that.</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>She told Price she wanted to join the Police E...</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The prime minister is keen to use the autumn p...</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Those competencies include mastering fundament...</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>His platform contains plans to fund drainage p...</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"It's a start.\"</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"She is not asking for anything over the top, ...</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Justice Dinakaran had maintained that he had n...</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  formality\n",
       "0  Tang was employed at private-equity firm Fried...   0.400000\n",
       "1  San Francisco Mayor Gavin Newsom's withdrawal ...   0.666667\n",
       "2                   lol nothing worrying about that.   0.033333\n",
       "3  She told Price she wanted to join the Police E...   0.500000\n",
       "4  The prime minister is keen to use the autumn p...   0.800000\n",
       "5  Those competencies include mastering fundament...   0.666667\n",
       "6  His platform contains plans to fund drainage p...   0.633333\n",
       "7                                    \"It's a start.\"   0.200000\n",
       "8  \"She is not asking for anything over the top, ...   0.600000\n",
       "9  Justice Dinakaran had maintained that he had n...   0.633333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate the train and test data, remove the domain column and rename the normalized_score column to formality\n",
    "data1 = pd.concat([df_train, df_test])\n",
    "data1 = data1.drop(columns=[\"domain\", \"avg_score\"])\n",
    "data1 = data1.rename(columns={\"normalized_score\": \"formality\"})\n",
    "print(len(data1))\n",
    "data1.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. FAME-MT Dataset (0 -> informal, 1 -> formal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tsv file\n",
    "formal = pd.read_csv(\"data/it-en.formal.tsv\", sep=\"\\t\", on_bad_lines=\"skip\")\n",
    "formal.columns = [\"italian\", \"english\"]\n",
    "informal = pd.read_csv(\"data/it-en.informal.tsv\", sep=\"\\t\", on_bad_lines=\"skip\")\n",
    "informal.columns = [\"italian\", \"english\"]\n",
    "\n",
    "# drop rows with NaN values\n",
    "formal = formal.dropna()\n",
    "informal = informal.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>italian</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ma è uscito dal corpo, adesso.</td>\n",
       "      <td>But it's out of the body now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ho paura, Elliot.</td>\n",
       "      <td>- I'm scared, Elliot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bella carta da parati per il desktop scaricare...</td>\n",
       "      <td>Charming desktop wallpapers backgrounds - 1440...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- Felice di conoscervi.</td>\n",
       "      <td>- Pleased to meet you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E sicuramente, sei un cazzone di un ufficiale ...</td>\n",
       "      <td>And sure enough, you've been an official assho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ma c'e' ancora un sospetto di omicidio e seque...</td>\n",
       "      <td>But we still have a murder and kidnapping susp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Acquista i biglietti per il Gabba</td>\n",
       "      <td>Grab tickets for the Gabba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lei vive in un villaggio carino dove ci sono u...</td>\n",
       "      <td>She lives in a cute village where there are lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Quindi il tuo elisir funziona.</td>\n",
       "      <td>So your elixir works.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gokudo Video Recensioni Commenti Maggiori info...</td>\n",
       "      <td>Gokudo Videos Reviews Comments More Info</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             italian  \\\n",
       "0                     Ma è uscito dal corpo, adesso.   \n",
       "1                                  Ho paura, Elliot.   \n",
       "2  Bella carta da parati per il desktop scaricare...   \n",
       "3                            - Felice di conoscervi.   \n",
       "4  E sicuramente, sei un cazzone di un ufficiale ...   \n",
       "5  Ma c'e' ancora un sospetto di omicidio e seque...   \n",
       "6                  Acquista i biglietti per il Gabba   \n",
       "7  Lei vive in un villaggio carino dove ci sono u...   \n",
       "8                     Quindi il tuo elisir funziona.   \n",
       "9  Gokudo Video Recensioni Commenti Maggiori info...   \n",
       "\n",
       "                                             english  \n",
       "0                      But it's out of the body now.  \n",
       "1                              - I'm scared, Elliot.  \n",
       "2  Charming desktop wallpapers backgrounds - 1440...  \n",
       "3                             - Pleased to meet you.  \n",
       "4  And sure enough, you've been an official assho...  \n",
       "5  But we still have a murder and kidnapping susp...  \n",
       "6                         Grab tickets for the Gabba  \n",
       "7  She lives in a cute village where there are lo...  \n",
       "8                              So your elixir works.  \n",
       "9           Gokudo Videos Reviews Comments More Info  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informal.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96735\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>formality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Listed are cams in category Neu | Show all Cat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weather forecast Arraial d Ajuda this week Sunday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yeah, you know, I'm not one for sentimental crap.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For the same reasons, and taking into account ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Restaurants West End Village</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amazingly enough, this program can eliminate t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sorry, Mariana called, then Jude needed me, an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What Wikipedia say about CContent of green cof...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Download Underground Tour game...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Will you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  formality\n",
       "0  Listed are cams in category Neu | Show all Cat...          0\n",
       "1  Weather forecast Arraial d Ajuda this week Sunday          0\n",
       "2  Yeah, you know, I'm not one for sentimental crap.          0\n",
       "3  For the same reasons, and taking into account ...          1\n",
       "4                       Restaurants West End Village          0\n",
       "5  Amazingly enough, this program can eliminate t...          1\n",
       "6  Sorry, Mariana called, then Jude needed me, an...          0\n",
       "7  What Wikipedia say about CContent of green cof...          0\n",
       "8                  Download Underground Tour game...          0\n",
       "9                                        Will you...          0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate the formal and informal data, add a column formality with values 1 for formal and 0 for informal and shuffle the data\n",
    "formal[\"formality\"] = 1\n",
    "informal[\"formality\"] = 0\n",
    "data2 = pd.concat([formal, informal])\n",
    "data2 = data2.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "data2 = data2.drop(columns=[\"italian\"])\n",
    "data2 = data2.rename(columns={\"english\": \"sentence\"})\n",
    "print(len(data2))\n",
    "data2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-classification\", model=\"LenDigLearn/formality-classifier-mdeberta-v3-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_mdeberta = \"s-nlp/mdeberta-base-formality-ranker\"\n",
    "tokenizer_mdeberta = AutoTokenizer.from_pretrained(model_name_mdeberta)\n",
    "model_mdeberta = AutoModelForSequenceClassification.from_pretrained(model_name_mdeberta)\n",
    "\n",
    "model_name_xlmr = \"s-nlp/xlmr_formality_classifier\"\n",
    "tokenizer_xlmr = AutoTokenizer.from_pretrained(model_name_xlmr)\n",
    "model_xlmr = AutoModelForSequenceClassification.from_pretrained(model_name_xlmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_formality_probability(text, tokenizer, model):\n",
    "    \"\"\"\n",
    "    Given a text, this function tokenizes the input,\n",
    "    runs inference through the model, and returns the softmax probability\n",
    "    for the \"formal\" label (assumed label 1).\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )\n",
    "    # Run inference; ensure tensors are on the same device as model\n",
    "    outputs = model(**inputs)\n",
    "    # Compute softmax over logits to get probabilities\n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "    # Return the probability for label 1 (\"formal\")\n",
    "    return probabilities[0][1].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inference and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentences1 = data1[\"sentence\"].tolist()[:500]\n",
    "sample_sentences2 = data2[\"sentence\"].tolist()[:500]\n",
    "\n",
    "y_true1 = np.array(data1[\"formality\"][:500].tolist())\n",
    "y_true2 = np.array(data2[\"formality\"][:500].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Data 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 mdeberta-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1_mdebertav3 = []\n",
    "for text in sample_sentences1:\n",
    "    results1_mdebertav3.append(pipe(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the label \n",
    "labels1_mdebertav3 = [result[0][\"label\"] for result in results1_mdebertav3]\n",
    "\n",
    "# convert formal to 1 and informal to 0 and neutral to 0.5\n",
    "labels1_mdebertav3 = [1 if label == \"formal\" else 0 if label == \"informal\" else 0.5 for label in labels1_mdebertav3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>predictions</th>\n",
       "      <th>true_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tang was employed at private-equity firm Fried...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>San Francisco Mayor Gavin Newsom's withdrawal ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lol nothing worrying about that.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>She told Price she wanted to join the Police E...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The prime minister is keen to use the autumn p...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Those competencies include mastering fundament...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>His platform contains plans to fund drainage p...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"It's a start.\"</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"She is not asking for anything over the top, ...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Justice Dinakaran had maintained that he had n...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  predictions  true_labels\n",
       "0  Tang was employed at private-equity firm Fried...          0.5     0.400000\n",
       "1  San Francisco Mayor Gavin Newsom's withdrawal ...          1.0     0.666667\n",
       "2                   lol nothing worrying about that.          0.0     0.033333\n",
       "3  She told Price she wanted to join the Police E...          0.5     0.500000\n",
       "4  The prime minister is keen to use the autumn p...          1.0     0.800000\n",
       "5  Those competencies include mastering fundament...          1.0     0.666667\n",
       "6  His platform contains plans to fund drainage p...          0.5     0.633333\n",
       "7                                    \"It's a start.\"          0.0     0.200000\n",
       "8  \"She is not asking for anything over the top, ...          0.5     0.600000\n",
       "9  Justice Dinakaran had maintained that he had n...          1.0     0.633333"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show dataset with sentences, predictions and true labels\n",
    "df1_mdebertav3 = pd.DataFrame({\"sentence\": sample_sentences1, \"predictions\": labels1_mdebertav3, \"true_labels\": y_true1})\n",
    "df1_mdebertav3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Evaluation Metrics:\n",
      "MAE: 0.172\n",
      "MSE: 0.044\n",
      "RMSE: 0.209\n",
      "R2: 0.149\n",
      "Pearson Correlation: 0.755\n",
      "Spearman Correlation: 0.744\n"
     ]
    }
   ],
   "source": [
    "# Compute metrics:\n",
    "mae = mean_absolute_error(y_true1, labels1_mdebertav3)\n",
    "mse = mean_squared_error(y_true1, labels1_mdebertav3)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_true1, labels1_mdebertav3)\n",
    "pearson_corr = pearsonr(y_true1, labels1_mdebertav3)[0]\n",
    "spearman_corr = spearmanr(y_true1, labels1_mdebertav3)[0]\n",
    "print(\"Continuous Evaluation Metrics:\")\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"MSE: {mse:.3f}\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"R2: {r2:.3f}\")\n",
    "print(f\"Pearson Correlation: {pearson_corr:.3f}\")\n",
    "print(f\"Spearman Correlation: {spearman_corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 xmlr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1_xmlr = []\n",
    "for sent in sample_sentences1:\n",
    "    prob_xlmr = get_formality_probability(sent, tokenizer_xlmr, model_xlmr)\n",
    "    results1_xmlr.append(prob_xlmr)\n",
    "\n",
    "results1_xmlr = 1 - np.array(results1_xmlr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the results and true labels binary\n",
    "b_results1_xmlr = np.where(results1_xmlr > 0.5, 1, 0)\n",
    "b_y_true1 = np.where(y_true1 > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>prediction</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tang was employed at private-equity firm Fried...</td>\n",
       "      <td>0.998518</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>San Francisco Mayor Gavin Newsom's withdrawal ...</td>\n",
       "      <td>0.998631</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lol nothing worrying about that.</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>She told Price she wanted to join the Police E...</td>\n",
       "      <td>0.998608</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The prime minister is keen to use the autumn p...</td>\n",
       "      <td>0.998626</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>At least seven people were killed and several ...</td>\n",
       "      <td>0.998641</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>The choice was not an easy one for Robert McCl...</td>\n",
       "      <td>0.998645</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Probably a 10 or 15 percent shade of cyan.</td>\n",
       "      <td>0.105627</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Here is a brief update on major DCF news that ...</td>\n",
       "      <td>0.998646</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Try http://www.mjelly.com/tags/free+mp3+ringto...</td>\n",
       "      <td>0.938650</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  prediction  true_label\n",
       "0    Tang was employed at private-equity firm Fried...    0.998518    0.400000\n",
       "1    San Francisco Mayor Gavin Newsom's withdrawal ...    0.998631    0.666667\n",
       "2                     lol nothing worrying about that.    0.002674    0.033333\n",
       "3    She told Price she wanted to join the Police E...    0.998608    0.500000\n",
       "4    The prime minister is keen to use the autumn p...    0.998626    0.800000\n",
       "..                                                 ...         ...         ...\n",
       "495  At least seven people were killed and several ...    0.998641    0.666667\n",
       "496  The choice was not an easy one for Robert McCl...    0.998645    0.600000\n",
       "497         Probably a 10 or 15 percent shade of cyan.    0.105627    0.533333\n",
       "498  Here is a brief update on major DCF news that ...    0.998646    0.933333\n",
       "499  Try http://www.mjelly.com/tags/free+mp3+ringto...    0.938650    0.300000\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show dataset with sentences, predictions and true labels\n",
    "df_results1_xmlr = pd.DataFrame({\"sentence\": sample_sentences1, \"prediction\": results1_xmlr, \"true_label\": y_true1})\n",
    "df_results1_xmlr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Evaluation Metrics:\n",
      "Accuracy:  0.684\n",
      "Precision: 0.616\n",
      "Recall:    0.968\n",
      "F1 Score:  0.753\n",
      "Confusion Matrix:\n",
      "[[101 150]\n",
      " [  8 241]]\n"
     ]
    }
   ],
   "source": [
    "# Compute metrics:\n",
    "acc = accuracy_score(b_y_true1, b_results1_xmlr)\n",
    "prec = precision_score(b_y_true1, b_results1_xmlr)\n",
    "rec = recall_score(b_y_true1, b_results1_xmlr)\n",
    "f1 = f1_score(b_y_true1, b_results1_xmlr)\n",
    "cm = confusion_matrix(b_y_true1, b_results1_xmlr)\n",
    "\n",
    "print(\"Binary Evaluation Metrics:\")\n",
    "print(f\"Accuracy:  {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall:    {rec:.3f}\")\n",
    "print(f\"F1 Score:  {f1:.3f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Continuous classification\n",
    "\n",
    "they don't make a lot of sense because the models are supposed to be confident and output simply formal or informal with strong confidence. instead the dataset is meant to see formality as a continuous variable, as if the sentences have various shades of formality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Evaluation Metrics:\n",
      "MAE: 0.370\n",
      "MSE: 0.173\n",
      "RMSE: 0.416\n",
      "R2: -2.364\n",
      "Pearson Correlation: 0.618\n",
      "Spearman Correlation: 0.690\n"
     ]
    }
   ],
   "source": [
    "# Compute metrics:\n",
    "mae = mean_absolute_error(y_true1, results1_xmlr)\n",
    "mse = mean_squared_error(y_true1, results1_xmlr)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_true1, results1_xmlr)\n",
    "pearson_corr = pearsonr(y_true1, results1_xmlr)[0]\n",
    "spearman_corr = spearmanr(y_true1, results1_xmlr)[0]\n",
    "print(\"Continuous Evaluation Metrics:\")\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"MSE: {mse:.3f}\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"R2: {r2:.3f}\")\n",
    "print(f\"Pearson Correlation: {pearson_corr:.3f}\")\n",
    "print(f\"Spearman Correlation: {spearman_corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1_mdeberta = []\n",
    "for sent in sample_sentences1:\n",
    "    prob_mdberta = get_formality_probability(sent, tokenizer_mdeberta, model_mdeberta)\n",
    "    results1_mdeberta.append(prob_mdberta)\n",
    "\n",
    "results1_mdeberta = 1 - np.array(results1_mdeberta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Data 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 mdeberta-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2_mdebertav3 = []\n",
    "for text in sample_sentences2:\n",
    "    results2_mdebertav3.append(pipe(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the label \n",
    "labels2_mdebertav3 = [result[0][\"label\"] for result in results2_mdebertav3]\n",
    "\n",
    "# convert formal to 1 and informal to 0 and neutral to 0.5\n",
    "labels2_mdebertav3 = [1 if label == \"formal\" else 0 if label == \"informal\" else 0.5 for label in labels2_mdebertav3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>predictions</th>\n",
       "      <th>true_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Listed are cams in category Neu | Show all Cat...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weather forecast Arraial d Ajuda this week Sunday</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yeah, you know, I'm not one for sentimental crap.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For the same reasons, and taking into account ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Restaurants West End Village</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>In encouraging people to sign the petition, Ar...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Mr Ocampo told the BBC that the ICC, after inv...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>He really is.</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Copyright The content and work on pages create...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>(5) Sheila Jasanoff, born in Calcutta but educ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  predictions  \\\n",
       "0    Listed are cams in category Neu | Show all Cat...          0.5   \n",
       "1    Weather forecast Arraial d Ajuda this week Sunday          0.5   \n",
       "2    Yeah, you know, I'm not one for sentimental crap.          0.0   \n",
       "3    For the same reasons, and taking into account ...          1.0   \n",
       "4                         Restaurants West End Village          0.5   \n",
       "..                                                 ...          ...   \n",
       "185  In encouraging people to sign the petition, Ar...          0.5   \n",
       "186  Mr Ocampo told the BBC that the ICC, after inv...          1.0   \n",
       "187                                      He really is.          0.5   \n",
       "188  Copyright The content and work on pages create...          1.0   \n",
       "189  (5) Sheila Jasanoff, born in Calcutta but educ...          1.0   \n",
       "\n",
       "     true_labels  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              1  \n",
       "4              0  \n",
       "..           ...  \n",
       "185            1  \n",
       "186            1  \n",
       "187            0  \n",
       "188            1  \n",
       "189            1  \n",
       "\n",
       "[190 rows x 3 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show dataset with sentences, predictions and true labels\n",
    "df2_mdebertav3 = pd.DataFrame({\"sentence\": sample_sentences2, \"predictions\": labels2_mdebertav3, \"true_labels\": y_true2})\n",
    "df2_mdebertav3.head(190)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Evaluation Metrics:\n",
      "MAE: 0.245\n",
      "MSE: 0.141\n",
      "RMSE: 0.376\n",
      "R2: 0.433\n",
      "Pearson Correlation: 0.666\n",
      "Spearman Correlation: 0.666\n"
     ]
    }
   ],
   "source": [
    "# Compute metrics:\n",
    "mae = mean_absolute_error(y_true2, labels2_mdebertav3)\n",
    "mse = mean_squared_error(y_true2, labels2_mdebertav3)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_true2, labels2_mdebertav3)\n",
    "pearson_corr = pearsonr(y_true2, labels2_mdebertav3)[0]\n",
    "spearman_corr = spearmanr(y_true2, labels2_mdebertav3)[0]\n",
    "print(\"Continuous Evaluation Metrics:\")\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"MSE: {mse:.3f}\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"R2: {r2:.3f}\")\n",
    "print(f\"Pearson Correlation: {pearson_corr:.3f}\")\n",
    "print(f\"Spearman Correlation: {spearman_corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 xmlr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2_xmlr = []\n",
    "for sent in sample_sentences2:\n",
    "    prob_xlmr = get_formality_probability(sent, tokenizer_xlmr, model_xlmr)\n",
    "    results2_xmlr.append(prob_xlmr)\n",
    "\n",
    "results2_xmlr = 1 - np.array(results2_xmlr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the results and true labels binary\n",
    "b_results2_xmlr = np.where(results2_xmlr > 0.5, 1, 0)\n",
    "b_y_true2 = np.where(y_true2 > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>prediction</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Listed are cams in category Neu | Show all Cat...</td>\n",
       "      <td>0.055602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weather forecast Arraial d Ajuda this week Sunday</td>\n",
       "      <td>0.052648</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yeah, you know, I'm not one for sentimental crap.</td>\n",
       "      <td>0.131297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For the same reasons, and taking into account ...</td>\n",
       "      <td>0.998615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Restaurants West End Village</td>\n",
       "      <td>0.194481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Since our arrival, while traveling in a taxi t...</td>\n",
       "      <td>0.998627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Error rates are usually very low—1 error in ev...</td>\n",
       "      <td>0.998640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Member contact information may be provided to ...</td>\n",
       "      <td>0.998604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>7. Our all products are in ex-work price, Most...</td>\n",
       "      <td>0.013378</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Take time to prepare in advance.</td>\n",
       "      <td>0.998673</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  prediction  true_label\n",
       "0    Listed are cams in category Neu | Show all Cat...    0.055602           0\n",
       "1    Weather forecast Arraial d Ajuda this week Sunday    0.052648           0\n",
       "2    Yeah, you know, I'm not one for sentimental crap.    0.131297           0\n",
       "3    For the same reasons, and taking into account ...    0.998615           1\n",
       "4                         Restaurants West End Village    0.194481           0\n",
       "..                                                 ...         ...         ...\n",
       "495  Since our arrival, while traveling in a taxi t...    0.998627           1\n",
       "496  Error rates are usually very low—1 error in ev...    0.998640           1\n",
       "497  Member contact information may be provided to ...    0.998604           1\n",
       "498  7. Our all products are in ex-work price, Most...    0.013378           0\n",
       "499                   Take time to prepare in advance.    0.998673           1\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show dataset with sentences, predictions and true labels\n",
    "df_results2_xmlr = pd.DataFrame({\"sentence\": sample_sentences2, \"prediction\": results2_xmlr, \"true_label\": y_true2})\n",
    "df_results2_xmlr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Evaluation Metrics:\n",
      "Accuracy:  0.786\n",
      "Precision: 0.713\n",
      "Recall:    0.989\n",
      "F1 Score:  0.828\n",
      "Confusion Matrix:\n",
      "[[135 104]\n",
      " [  3 258]]\n"
     ]
    }
   ],
   "source": [
    "# Compute metrics:\n",
    "acc = accuracy_score(b_y_true2, b_results2_xmlr)\n",
    "prec = precision_score(b_y_true2, b_results2_xmlr)\n",
    "rec = recall_score(b_y_true2, b_results2_xmlr)\n",
    "f1 = f1_score(b_y_true2, b_results2_xmlr)\n",
    "cm = confusion_matrix(b_y_true2, b_results2_xmlr)\n",
    "\n",
    "print(\"Binary Evaluation Metrics:\")\n",
    "print(f\"Accuracy:  {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall:    {rec:.3f}\")\n",
    "print(f\"F1 Score:  {f1:.3f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continuous classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Evaluation Metrics:\n",
      "MAE: 0.220\n",
      "MSE: 0.183\n",
      "RMSE: 0.428\n",
      "R2: 0.266\n",
      "Pearson Correlation: 0.671\n",
      "Spearman Correlation: 0.782\n"
     ]
    }
   ],
   "source": [
    "# Compute metrics:\n",
    "mae = mean_absolute_error(y_true2, results2_xmlr)\n",
    "mse = mean_squared_error(y_true2, results2_xmlr)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_true2, results2_xmlr)\n",
    "pearson_corr = pearsonr(y_true2, results2_xmlr)[0]\n",
    "spearman_corr = spearmanr(y_true2, results2_xmlr)[0]\n",
    "print(\"Continuous Evaluation Metrics:\")\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"MSE: {mse:.3f}\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"R2: {r2:.3f}\")\n",
    "print(f\"Pearson Correlation: {pearson_corr:.3f}\")\n",
    "print(f\"Spearman Correlation: {spearman_corr:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jetbrains_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
