{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/jetbrains_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, roc_auc_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pavlick and Tetreault Formality Scores (0 -> informal, 1 -> formal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"osyvokon/pavlick-formality-scores\")\n",
    "\n",
    "train_data = dataset[\"train\"]\n",
    "test_data = dataset[\"test\"] \n",
    "\n",
    "df_train = pd.DataFrame(train_data.to_pandas())  \n",
    "df_test = pd.DataFrame(test_data.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>Tang was employed at private-equity firm Fried...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news</td>\n",
       "      <td>1.0</td>\n",
       "      <td>San Francisco Mayor Gavin Newsom's withdrawal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>answers</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>lol nothing worrying about that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>0.0</td>\n",
       "      <td>She told Price she wanted to join the Police E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news</td>\n",
       "      <td>1.8</td>\n",
       "      <td>The prime minister is keen to use the autumn p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>blog</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Those competencies include mastering fundament...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>news</td>\n",
       "      <td>0.8</td>\n",
       "      <td>His platform contains plans to fund drainage p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>answers</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>\"It's a start.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>news</td>\n",
       "      <td>0.6</td>\n",
       "      <td>\"She is not asking for anything over the top, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>news</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Justice Dinakaran had maintained that he had n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    domain  avg_score                                           sentence\n",
       "0     news       -0.6  Tang was employed at private-equity firm Fried...\n",
       "1     news        1.0  San Francisco Mayor Gavin Newsom's withdrawal ...\n",
       "2  answers       -2.8                   lol nothing worrying about that.\n",
       "3     news        0.0  She told Price she wanted to join the Police E...\n",
       "4     news        1.8  The prime minister is keen to use the autumn p...\n",
       "5     blog        1.0  Those competencies include mastering fundament...\n",
       "6     news        0.8  His platform contains plans to fund drainage p...\n",
       "7  answers       -1.8                                    \"It's a start.\"\n",
       "8     news        0.6  \"She is not asking for anything over the top, ...\n",
       "9     news        0.8  Justice Dinakaran had maintained that he had n..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9274.000000\n",
       "mean       -0.044080\n",
       "std         1.349061\n",
       "min        -3.000000\n",
       "25%        -1.000000\n",
       "50%         0.000000\n",
       "75%         1.000000\n",
       "max         3.000000\n",
       "Name: avg_score, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data exploration of avg_score\n",
    "df_train[\"avg_score\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"normalized_score\"] = (df_train[\"avg_score\"] + 3) / 6\n",
    "df_test[\"normalized_score\"] = (df_test[\"avg_score\"] + 3) / 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11274\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>formality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tang was employed at private-equity firm Fried...</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>San Francisco Mayor Gavin Newsom's withdrawal ...</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lol nothing worrying about that.</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>She told Price she wanted to join the Police E...</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The prime minister is keen to use the autumn p...</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Those competencies include mastering fundament...</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>His platform contains plans to fund drainage p...</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"It's a start.\"</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"She is not asking for anything over the top, ...</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Justice Dinakaran had maintained that he had n...</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  formality\n",
       "0  Tang was employed at private-equity firm Fried...   0.400000\n",
       "1  San Francisco Mayor Gavin Newsom's withdrawal ...   0.666667\n",
       "2                   lol nothing worrying about that.   0.033333\n",
       "3  She told Price she wanted to join the Police E...   0.500000\n",
       "4  The prime minister is keen to use the autumn p...   0.800000\n",
       "5  Those competencies include mastering fundament...   0.666667\n",
       "6  His platform contains plans to fund drainage p...   0.633333\n",
       "7                                    \"It's a start.\"   0.200000\n",
       "8  \"She is not asking for anything over the top, ...   0.600000\n",
       "9  Justice Dinakaran had maintained that he had n...   0.633333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate the train and test data, remove the domain column and rename the normalized_score column to formality\n",
    "data1 = pd.concat([df_train, df_test])\n",
    "data1 = data1.drop(columns=[\"domain\", \"avg_score\"])\n",
    "data1 = data1.rename(columns={\"normalized_score\": \"formality\"})\n",
    "print(len(data1))\n",
    "data1.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. FAME-MT Dataset (0 -> informal, 1 -> formal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tsv file\n",
    "formal = pd.read_csv(\"it-en.formal.tsv\", sep=\"\\t\", on_bad_lines=\"skip\")\n",
    "formal.columns = [\"italian\", \"english\"]\n",
    "informal = pd.read_csv(\"it-en.informal.tsv\", sep=\"\\t\", on_bad_lines=\"skip\")\n",
    "informal.columns = [\"italian\", \"english\"]\n",
    "\n",
    "# drop rows with NaN values\n",
    "formal = formal.dropna()\n",
    "informal = informal.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>italian</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ma è uscito dal corpo, adesso.</td>\n",
       "      <td>But it's out of the body now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ho paura, Elliot.</td>\n",
       "      <td>- I'm scared, Elliot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bella carta da parati per il desktop scaricare...</td>\n",
       "      <td>Charming desktop wallpapers backgrounds - 1440...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- Felice di conoscervi.</td>\n",
       "      <td>- Pleased to meet you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E sicuramente, sei un cazzone di un ufficiale ...</td>\n",
       "      <td>And sure enough, you've been an official assho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ma c'e' ancora un sospetto di omicidio e seque...</td>\n",
       "      <td>But we still have a murder and kidnapping susp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Acquista i biglietti per il Gabba</td>\n",
       "      <td>Grab tickets for the Gabba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lei vive in un villaggio carino dove ci sono u...</td>\n",
       "      <td>She lives in a cute village where there are lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Quindi il tuo elisir funziona.</td>\n",
       "      <td>So your elixir works.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gokudo Video Recensioni Commenti Maggiori info...</td>\n",
       "      <td>Gokudo Videos Reviews Comments More Info</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             italian  \\\n",
       "0                     Ma è uscito dal corpo, adesso.   \n",
       "1                                  Ho paura, Elliot.   \n",
       "2  Bella carta da parati per il desktop scaricare...   \n",
       "3                            - Felice di conoscervi.   \n",
       "4  E sicuramente, sei un cazzone di un ufficiale ...   \n",
       "5  Ma c'e' ancora un sospetto di omicidio e seque...   \n",
       "6                  Acquista i biglietti per il Gabba   \n",
       "7  Lei vive in un villaggio carino dove ci sono u...   \n",
       "8                     Quindi il tuo elisir funziona.   \n",
       "9  Gokudo Video Recensioni Commenti Maggiori info...   \n",
       "\n",
       "                                             english  \n",
       "0                      But it's out of the body now.  \n",
       "1                              - I'm scared, Elliot.  \n",
       "2  Charming desktop wallpapers backgrounds - 1440...  \n",
       "3                             - Pleased to meet you.  \n",
       "4  And sure enough, you've been an official assho...  \n",
       "5  But we still have a murder and kidnapping susp...  \n",
       "6                         Grab tickets for the Gabba  \n",
       "7  She lives in a cute village where there are lo...  \n",
       "8                              So your elixir works.  \n",
       "9           Gokudo Videos Reviews Comments More Info  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informal.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96735\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>formality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Listed are cams in category Neu | Show all Cat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weather forecast Arraial d Ajuda this week Sunday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yeah, you know, I'm not one for sentimental crap.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For the same reasons, and taking into account ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Restaurants West End Village</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amazingly enough, this program can eliminate t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sorry, Mariana called, then Jude needed me, an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What Wikipedia say about CContent of green cof...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Download Underground Tour game...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Will you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  formality\n",
       "0  Listed are cams in category Neu | Show all Cat...          0\n",
       "1  Weather forecast Arraial d Ajuda this week Sunday          0\n",
       "2  Yeah, you know, I'm not one for sentimental crap.          0\n",
       "3  For the same reasons, and taking into account ...          1\n",
       "4                       Restaurants West End Village          0\n",
       "5  Amazingly enough, this program can eliminate t...          1\n",
       "6  Sorry, Mariana called, then Jude needed me, an...          0\n",
       "7  What Wikipedia say about CContent of green cof...          0\n",
       "8                  Download Underground Tour game...          0\n",
       "9                                        Will you...          0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate the formal and informal data, add a column formality with values 1 for formal and 0 for informal and shuffle the data\n",
    "formal[\"formality\"] = 1\n",
    "informal[\"formality\"] = 0\n",
    "data2 = pd.concat([formal, informal])\n",
    "data2 = data2.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "data2 = data2.drop(columns=[\"italian\"])\n",
    "data2 = data2.rename(columns={\"english\": \"sentence\"})\n",
    "print(len(data2))\n",
    "data2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_mdeberta = \"s-nlp/mdeberta-base-formality-ranker\"\n",
    "tokenizer_mdeberta = AutoTokenizer.from_pretrained(model_name_mdeberta)\n",
    "model_mdeberta = AutoModelForSequenceClassification.from_pretrained(model_name_mdeberta)\n",
    "\n",
    "model_name_xlmr = \"s-nlp/xlmr_formality_classifier\"\n",
    "tokenizer_xlmr = AutoTokenizer.from_pretrained(model_name_xlmr)\n",
    "model_xlmr = AutoModelForSequenceClassification.from_pretrained(model_name_xlmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_formality_probability(text, tokenizer, model):\n",
    "    \"\"\"\n",
    "    Given a text, this function tokenizes the input,\n",
    "    runs inference through the model, and returns the softmax probability\n",
    "    for the \"formal\" label (assumed label 1).\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )\n",
    "    # Run inference; ensure tensors are on the same device as model\n",
    "    outputs = model(**inputs)\n",
    "    # Compute softmax over logits to get probabilities\n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "    # Return the probability for label 1 (\"formal\")\n",
    "    return probabilities[0][1].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trained and test n-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7521064301552106\n"
     ]
    }
   ],
   "source": [
    "texts_1 = data1[\"sentence\"]\n",
    "labels_1 = [1 if i > 0.5 else 0 for i in data1[\"formality\"]]\n",
    "\n",
    "char_vectorizer_1 = CountVectorizer(analyzer='char', ngram_range=(2,6), min_df=1, max_df=1.0)\n",
    "\n",
    "# Create a pipeline with the vectorizer and a classifier\n",
    "pipeline_1 = make_pipeline(char_vectorizer_1, LogisticRegression(max_iter=1000))\n",
    "\n",
    "# Split data for training and testing (example split)\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(texts_1, labels_1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "pipeline_1.fit(X_train_1, y_train_1)\n",
    "\n",
    "# Evaluate the classifier\n",
    "predictions_1 = pipeline_1.predict(X_test_1)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_1, predictions_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7704315886134068\n",
      "Recall: 0.730836236933798\n",
      "F1-Score: 0.7501117568171658\n",
      "Confusion Matrix:\n",
      " [[857 250]\n",
      " [309 839]]\n",
      "ROC-AUC: 0.7525003226222738\n"
     ]
    }
   ],
   "source": [
    "prec = precision_score(y_test_1, predictions_1, average='binary')  \n",
    "rec = recall_score(y_test_1, predictions_1, average='binary')\n",
    "f1 = f1_score(y_test_1, predictions_1, average='binary')\n",
    "conf_mat = confusion_matrix(y_test_1, predictions_1)\n",
    "roc_auc = roc_auc_score(y_test_1, predictions_1)\n",
    "\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_mat)\n",
    "print(\"ROC-AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9331679330128703\n"
     ]
    }
   ],
   "source": [
    "texts = data2[\"sentence\"]\n",
    "labels = data2[\"formality\"]\n",
    "\n",
    "char_vectorizer = CountVectorizer(analyzer='char', ngram_range=(2,6), min_df=1, max_df=1.0)\n",
    "\n",
    "# Create a pipeline with the vectorizer and a classifier\n",
    "pipeline = make_pipeline(char_vectorizer, LogisticRegression(max_iter=1000))\n",
    "\n",
    "# Split data for training and testing (example split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier\n",
    "predictions = pipeline.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9456971452213487\n",
      "Recall: 0.9225103420441934\n",
      "F1-Score: 0.9339598549466265\n",
      "Confusion Matrix:\n",
      " [[8911  525]\n",
      " [ 768 9143]]\n",
      "ROC-AUC: 0.9334361799241738\n"
     ]
    }
   ],
   "source": [
    "prec = precision_score(y_test, predictions, average='binary')  # adjust 'binary' or 'macro' based on your data\n",
    "rec = recall_score(y_test, predictions, average='binary')\n",
    "f1 = f1_score(y_test, predictions, average='binary')\n",
    "conf_mat = confusion_matrix(y_test, predictions)\n",
    "roc_auc = roc_auc_score(y_test, predictions)\n",
    "\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_mat)\n",
    "print(\"ROC-AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_LLM = \"EleutherAI/gpt-neo-1.3B\"\n",
    "tokenizer_LLM = AutoTokenizer.from_pretrained(model_name_LLM)\n",
    "model_LLM = AutoModelForCausalLM.from_pretrained(model_name_LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted formality rating: 1\n"
     ]
    }
   ],
   "source": [
    "def predict_formality(text, tokenizer, model):\n",
    "    prompt = (f\"Please rate the following sentence's formality on a scale from 1 (very informal) to 5 (very formal).\\n\\n\"\n",
    "              f\"Sentence: \\\"{text}\\\"\\nFormality rating:\")\n",
    "    \n",
    "    # Encode the prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate output (adjust max_new_tokens as needed)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=5, temperature=0.0, do_sample=False)\n",
    "    \n",
    "    # Decode and extract the rating\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Extract the rating number from the response (simple approach)\n",
    "    rating = response.split(\"Formality rating:\")[-1].strip().split()[0]\n",
    "    return rating\n",
    "\n",
    "# Example usage:\n",
    "sample_text = \"Dear Sir or Madam,\"\n",
    "rating = predict_formality(sample_text, tokenizer_LLM, model_LLM)\n",
    "print(\"Predicted formality rating:\", rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(text, tokenizer, model):\n",
    "    # Combine conversation history with the new input\n",
    "    prompt = text\n",
    "    \n",
    "    # Tokenize the prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate output with sampling and a set maximum of new tokens\n",
    "    outputs = model.generate(\n",
    "        **inputs, \n",
    "        max_new_tokens=50,  \n",
    "        do_sample=False,\n",
    "        top_k=50,  # optionally, control diversity with top_k sampling\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    # Decode the output and extract the response (remove the prompt)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Optionally, remove the original prompt from the response\n",
    "    response = response.replace(prompt, \"\").strip()\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a writer, a mother, a wife, a daughter, a sister, a friend, a lover, a friend of Jesus, a friend of the world, a friend of the poor, a friend of the world’s\n"
     ]
    }
   ],
   "source": [
    "user_input = \"who are you?\"\n",
    "response = chat(user_input, tokenizer_LLM, model_LLM)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentences1 = data1[\"sentence\"].tolist()[:100]\n",
    "sample_sentences2 = data2[\"sentence\"].tolist()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = []\n",
    "for i, sent in enumerate(sample_sentences1):\n",
    "    prob_xlmr = get_formality_probability(sent, tokenizer_xlmr, model_xlmr)\n",
    "    prob_mdberta = get_formality_probability(sent, tokenizer_mdeberta, model_mdeberta)\n",
    "    results1.append({\n",
    "        \"sentence\": sent,\n",
    "        \"xlmr_formality_prob\": prob_xlmr,\n",
    "        \"mdeberta-base-formality-ranker\": prob_mdberta})\n",
    "\n",
    "df_results1 = pd.DataFrame(results1)\n",
    "\n",
    "# invert the one with zeros\n",
    "df_results1[\"xlmr_formality_prob\"] = 1 - df_results1[\"xlmr_formality_prob\"]\n",
    "df_results1[\"mdeberta-base-formality-ranker\"] = 1 - df_results1[\"mdeberta-base-formality-ranker\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0013433765852823853, 0.9915924072265625)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_formality_probability(\"Congratulations on achieving this ambitious objective.\", tokenizer_xlmr, model_xlmr), get_formality_probability(\"I am a student\", tokenizer_mdeberta, model_mdeberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 sentences\n",
      "Processed 10 sentences\n",
      "Processed 20 sentences\n",
      "Processed 30 sentences\n",
      "Processed 40 sentences\n",
      "Processed 50 sentences\n",
      "Processed 60 sentences\n",
      "Processed 70 sentences\n",
      "Processed 80 sentences\n",
      "Processed 90 sentences\n"
     ]
    }
   ],
   "source": [
    "results2 = []\n",
    "for i, sent in enumerate(sample_sentences2):\n",
    "    prob_xlmr = get_formality_probability(sent, tokenizer_xlmr, model_xlmr)\n",
    "    prob_mdberta = get_formality_probability(sent, tokenizer_mdeberta, model_mdeberta)\n",
    "    results2.append({\n",
    "        \"sentence\": sent,\n",
    "        \"xlmr_formality_prob\": prob_xlmr,\n",
    "        \"mdeberta-base-formality-ranker\": prob_mdberta})\n",
    "df_results2 = pd.DataFrame(results2)\n",
    "\n",
    "# invert the one with zeros\n",
    "df_results2[\"xlmr_formality_prob\"] = 1 - df_results2[\"xlmr_formality_prob\"]\n",
    "df_results2[\"mdeberta-base-formality-ranker\"] = 1 - df_results2[\"mdeberta-base-formality-ranker\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count    100.000000\n",
       " mean       0.781186\n",
       " std        0.385278\n",
       " min        0.002608\n",
       " 25%        0.840318\n",
       " 50%        0.998527\n",
       " 75%        0.998639\n",
       " max        0.998666\n",
       " Name: xlmr_formality_prob, dtype: float64,\n",
       " count    100.000000\n",
       " mean       0.013183\n",
       " std        0.034896\n",
       " min        0.000891\n",
       " 25%        0.002557\n",
       " 50%        0.004460\n",
       " 75%        0.007833\n",
       " max        0.307690\n",
       " Name: mdeberta-base-formality-ranker, dtype: float64,\n",
       " count    100.000000\n",
       " mean       0.715734\n",
       " std        0.420436\n",
       " min        0.003262\n",
       " 25%        0.185834\n",
       " 50%        0.997417\n",
       " 75%        0.998625\n",
       " max        0.998677\n",
       " Name: xlmr_formality_prob, dtype: float64,\n",
       " count    100.000000\n",
       " mean       0.030187\n",
       " std        0.102882\n",
       " min        0.000832\n",
       " 25%        0.002577\n",
       " 50%        0.004249\n",
       " 75%        0.011433\n",
       " max        0.738821\n",
       " Name: mdeberta-base-formality-ranker, dtype: float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyze the results\n",
    "df_results1[\"xlmr_formality_prob\"].describe(), df_results1[\"mdeberta-base-formality-ranker\"].describe(), df_results2[\"xlmr_formality_prob\"].describe(), df_results2[\"mdeberta-base-formality-ranker\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of Predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>normalized_score</th>\n",
       "      <th>xlmr_formality_prob</th>\n",
       "      <th>mdeberta-base-formality-ranker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saleh said the detainees told interrogators th...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.998518</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i own this board, now.</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.998631</td>\n",
       "      <td>0.005246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>will lead you into blind alleys.</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.001454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you have any questions or wish to speak fur...</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.998608</td>\n",
       "      <td>0.002493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>However, your case may be different.</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.998626</td>\n",
       "      <td>0.036147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>There is much more that happened behind the sc...</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.998574</td>\n",
       "      <td>0.138463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>I realise that, as a libertarian, I might well...</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.996865</td>\n",
       "      <td>0.008894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>If you go below that, they can sue you.</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.998665</td>\n",
       "      <td>0.007308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Engadget assumes no responsibility for injury ...</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.998641</td>\n",
       "      <td>0.002122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>You have to make the kids pick up after themse...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.998588</td>\n",
       "      <td>0.004456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  normalized_score  \\\n",
       "0   Saleh said the detainees told interrogators th...          0.666667   \n",
       "1                              i own this board, now.          0.125000   \n",
       "2                    will lead you into blind alleys.          0.166667   \n",
       "3   If you have any questions or wish to speak fur...          0.866667   \n",
       "4                However, your case may be different.          0.600000   \n",
       "..                                                ...               ...   \n",
       "95  There is much more that happened behind the sc...          0.791667   \n",
       "96  I realise that, as a libertarian, I might well...          0.533333   \n",
       "97            If you go below that, they can sue you.          0.366667   \n",
       "98  Engadget assumes no responsibility for injury ...          0.766667   \n",
       "99  You have to make the kids pick up after themse...          0.200000   \n",
       "\n",
       "    xlmr_formality_prob  mdeberta-base-formality-ranker  \n",
       "0              0.998518                        0.001700  \n",
       "1              0.998631                        0.005246  \n",
       "2              0.002674                        0.001454  \n",
       "3              0.998608                        0.002493  \n",
       "4              0.998626                        0.036147  \n",
       "..                  ...                             ...  \n",
       "95             0.998574                        0.138463  \n",
       "96             0.996865                        0.008894  \n",
       "97             0.998665                        0.007308  \n",
       "98             0.998641                        0.002122  \n",
       "99             0.998588                        0.004456  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the results with the human normalized scores (using the same order as sample_sentences)\n",
    "df_sample = df_test.head(100).copy()\n",
    "df_sample = df_sample.reset_index(drop=True)\n",
    "df_sample = pd.concat([df_sample, df_results1.drop(columns=\"sentence\")], axis=1)\n",
    "\n",
    "print(\"\\nComparison of Predictions:\")\n",
    "df_sample[[\"sentence\", \"normalized_score\", \"xlmr_formality_prob\", \"mdeberta-base-formality-ranker\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_sample[\"normalized_score\"]\n",
    "x = df_sample[\"xlmr_formality_prob\"]\n",
    "\n",
    "x = [1 if i > 0.5 else 0 for i in x]\n",
    "y = [1 if i > 0.5 else 0 for i in y] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Evaluation Metrics:\n",
      "Accuracy:  0.500\n",
      "Precision: 0.500\n",
      "Recall:    0.780\n",
      "F1 Score:  0.609\n",
      "Confusion Matrix:\n",
      "[[11 39]\n",
      " [11 39]]\n"
     ]
    }
   ],
   "source": [
    "binary_true = y  # ground truth binary labels\n",
    "binary_pred = x  # model binary predictions\n",
    "\n",
    "# Compute metrics:\n",
    "acc = accuracy_score(binary_true, binary_pred)\n",
    "prec = precision_score(binary_true, binary_pred)\n",
    "rec = recall_score(binary_true, binary_pred)\n",
    "f1 = f1_score(binary_true, binary_pred)\n",
    "cm = confusion_matrix(binary_true, binary_pred)\n",
    "\n",
    "print(\"Binary Evaluation Metrics:\")\n",
    "print(f\"Accuracy:  {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall:    {rec:.3f}\")\n",
    "print(f\"F1 Score:  {f1:.3f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Continuous Evaluation Metrics:\n",
      "Mean Absolute Error (MAE):  0.368\n",
      "Mean Squared Error (MSE):   0.177\n",
      "R² Score:                   -2.071\n",
      "Pearson Correlation:        0.600\n",
      "Spearman Correlation:       0.763\n"
     ]
    }
   ],
   "source": [
    "# Assume continuous_true and continuous_pred are the ground truth and model predictions,\n",
    "# with values between 0 and 1. For example:\n",
    "continuous_true = df_sample[\"normalized_score\"].tolist()\n",
    "continuous_pred = df_sample[\"xlmr_formality_prob\"].tolist()\n",
    "\n",
    "# Calculate error metrics:\n",
    "mae = mean_absolute_error(continuous_true, continuous_pred)\n",
    "mse = mean_squared_error(continuous_true, continuous_pred)\n",
    "r2 = r2_score(continuous_true, continuous_pred)\n",
    "\n",
    "# Calculate correlation coefficients:\n",
    "pearson_corr, _ = pearsonr(continuous_true, continuous_pred)\n",
    "spearman_corr, _ = spearmanr(continuous_true, continuous_pred)\n",
    "\n",
    "print(\"\\nContinuous Evaluation Metrics:\")\n",
    "print(f\"Mean Absolute Error (MAE):  {mae:.3f}\")\n",
    "print(f\"Mean Squared Error (MSE):   {mse:.3f}\")\n",
    "print(f\"R² Score:                   {r2:.3f}\")\n",
    "print(f\"Pearson Correlation:        {pearson_corr:.3f}\")\n",
    "print(f\"Spearman Correlation:       {spearman_corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Binary Evaluation Metrics:\n",
    "Accuracy:  0.670\n",
    "Precision: 0.605\n",
    "Recall:    0.980\n",
    "F1 Score:  0.748\n",
    "Confusion Matrix:\n",
    "[[18 32]\n",
    " [ 1 49]]\n",
    "\n",
    "Continuous Evaluation Metrics:\n",
    "Mean Absolute Error (MAE):  0.368\n",
    "Mean Squared Error (MSE):   0.177\n",
    "R² Score:                   -2.071\n",
    "Pearson Correlation:        0.600\n",
    "Spearman Correlation:       0.763"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jetbrains_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
